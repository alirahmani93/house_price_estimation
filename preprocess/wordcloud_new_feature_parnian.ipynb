{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install python-bidi\n",
        "pip install arabic-reshaper"
      ],
      "metadata": {
        "id": "8suMwv9GpLhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RFvDTC1oscV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "from bidi.algorithm import get_display\n",
        "import arabic_reshaper"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Post-2023-11-17.csv')"
      ],
      "metadata": {
        "id": "6vsn9OFNpw1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data preparing for counting**"
      ],
      "metadata": {
        "id": "X5_IZnvgp8hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_non_null_values(df):\n",
        "    non_null_values = {}\n",
        "    for column in df.columns:\n",
        "        non_null_values[column] = df[column].dropna().values\n",
        "    return non_null_values\n",
        "\n",
        "def extract_persian_words(text):\n",
        "    persian_words = re.findall(r'[\\u0600-\\u06FF\\s]+', text)\n",
        "    return persian_words\n",
        "\n",
        "def generate_word_cloud(word_counts):\n",
        "    reshaped_text = arabic_reshaper.reshape(' '.join(word_counts.keys()))\n",
        "    persian_text = get_display(reshaped_text)\n",
        "\n",
        "    wordcloud = WordCloud(font_path='/content/Mj_Farsi Simple Normal_0.ttf', background_color='white',\n",
        "                          width=800, height=400, regexp=r\"[\\u0600-\\u06FF]+\").generate_from_frequencies(word_counts)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def process_description(df):\n",
        "    df_description = df['description']\n",
        "    df_description_dist = df_description.str.split('|', expand=True)\n",
        "    df_description_dist = df_description_dist[[0, 3]]\n",
        "\n",
        "    series = df_description_dist[0].str.replace(r'[\\d*]+', '', regex=True)\n",
        "    series1 = series.str.split(',', expand=True)[0]\n",
        "    series2 = series1.str.split('_', expand=True)\n",
        "    series20 = series2[0].str.split(' ', expand=True)\n",
        "    series21 = series2[1].str.split(' ', expand=True)\n",
        "    series22 = series2[2].str.split(' ', expand=True)\n",
        "    series23 = series2[3].str.split(' ', expand=True)\n",
        "    series24 = series2[4].str.split(' ', expand=True)\n",
        "\n",
        "    series20_dict = extract_non_null_values(series20)\n",
        "    series21_dict = extract_non_null_values(series21)\n",
        "    series22_dict = extract_non_null_values(series22)\n",
        "    series23_dict = extract_non_null_values(series23)\n",
        "    series24_dict = extract_non_null_values(series24)\n",
        "\n",
        "    list_series20 = [series20_dict.get(i).tolist() for i in range(len(series20_dict.values()))]\n",
        "    list_series21 = [series21_dict.get(i).tolist() for i in range(len(series21_dict.values()))]\n",
        "    list_series22 = [series22_dict.get(i).tolist() for i in range(len(series22_dict.values()))]\n",
        "    list_series23 = [series23_dict.get(i).tolist() for i in range(len(series23_dict.values()))]\n",
        "    list_series24 = [series24_dict.get(i).tolist() for i in range(len(series24_dict.values()))]\n",
        "\n",
        "    flattened_list_series20 = [item for sublist in list_series20 for item in sublist]\n",
        "    flattened_list_series21 = [item for sublist in list_series21 for item in sublist]\n",
        "    flattened_list_series22 = [item for sublist in list_series22 for item in sublist]\n",
        "    flattened_list_series23 = [item for sublist in list_series23 for item in sublist]\n",
        "    flattened_list_series24 = [item for sublist in list_series24 for item in sublist]\n",
        "\n",
        "    list_series2 = [flattened_list_series20, flattened_list_series21, flattened_list_series22,\n",
        "                    flattened_list_series23, flattened_list_series24]\n",
        "    series0 = [item for sublist in list_series2 for item in sublist]\n",
        "\n",
        "    series3 = df_description_dist[3].str.replace(r'[\\d*]+', '', regex=True)\n",
        "    series3 = series3.str.split(',', expand=True)[0]\n",
        "    series3 = series3.str.replace(r'[\\d*]+', '', regex=True)\n",
        "    pattern = r'[\\u0600-\\u06FF\\s]+'\n",
        "    persian_words = series3.str.findall(pattern)\n",
        "    persian_words_list = persian_words.apply(lambda x: extract_persian_words(str(x)))\n",
        "    persian_words_list1 = persian_words_list.apply(lambda x: extract_persian_words(str(x)))\n",
        "    ser = pd.Series(persian_words_list1)\n",
        "    ser = ser.replace(' ', pd.NA)\n",
        "    ser = ser.dropna()\n",
        "    ser3 = [item for sublist in ser for item in sublist]\n",
        "    series_ser3 = pd.Series(ser3)\n",
        "    return series_ser3\n",
        "\n",
        "def process_title(df):\n",
        "    df['Contains_teras'] = df['title'].str.contains('تراس|بالکن', regex=True)\n",
        "    df['Contains_komod'] = df['title'].str.contains('کمد')\n",
        "    df['Contains_master'] = df['title'].str.contains('مستر')\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "6jXrD9aU9OxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0QDBnTqt9O0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MECiUWE19O2h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}